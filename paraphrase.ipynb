{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6gp0SoKl64k",
        "outputId": "9f9c37ce-59b8-4366-c98e-b352a9919adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "# import nltk\n",
        "# from nltk import bigrams\n",
        "# from nltk import ngrams"
      ],
      "metadata": {
        "id": "Rw3NCpxsl4h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "QbO-a8glHjhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = open('1000translations.txt', 'r')"
      ],
      "metadata": {
        "id": "rPnyGU7DH79b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paraphrase Generation"
      ],
      "metadata": {
        "id": "a5QXXsMfllqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')"
      ],
      "metadata": {
        "id": "QYcZ_rDlln67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using model from https://huggingface.co/eugenesiow/bart-paraphrase?text=Madam+President+%2C+coinciding+with+this+year+%27+s+first+part-session+of+the+European+Parliament+%2C+a+date+has+been+set+%2C+unfortunately+for+next+Thursday+%2C+in+Texas+in+America+%2C+for+the+execution+of+a+young+34+year-old+man+who+has+been+sentenced+to+death+.+We+shall+call+him+Mr+Hicks+.\n",
        "\n",
        "para_bart_large = open('para_bart.txt', 'w')\n",
        "\n",
        "while True:\n",
        "  input_sentence = reader.readline()\n",
        "  if not input_sentence:\n",
        "    break\n",
        "  batch = tokenizer(input_sentence, return_tensors='pt')\n",
        "  generated_ids = model.generate(batch['input_ids'])\n",
        "  generated_sentence = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "  ret_text = str(generated_sentence)[2:-2]\n",
        "  print(ret_text)\n",
        "  para_bart_large.write(ret_text)\n",
        "  para_bart_large.write('\\n')\n",
        "\n",
        "para_bart_large.close()"
      ],
      "metadata": {
        "id": "K5RDEmpnnKqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = open('1000translations.txt', 'r')"
      ],
      "metadata": {
        "id": "r5k3go-XsNYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
        "\n",
        "def paraphrase(\n",
        "    question,\n",
        "    num_beams=5,\n",
        "    num_beam_groups=5,\n",
        "    num_return_sequences=1,\n",
        "    repetition_penalty=10.0,\n",
        "    diversity_penalty=3.0,\n",
        "    no_repeat_ngram_size=2,\n",
        "    temperature=0.7,\n",
        "    max_length=128\n",
        "):\n",
        "    input_ids = tokenizer(\n",
        "        f'paraphrase: {question}',\n",
        "        return_tensors=\"pt\", padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    ).input_ids\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
        "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
        "        max_length=max_length, diversity_penalty=diversity_penalty\n",
        "    )\n",
        "\n",
        "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "EYrbsC2ZqoBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using model from https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base?text=Madam+President+%2C+coinciding+with+this+year+%27+s+first+part-session+of+the+European+Parliament+%2C+a+date+has+been+set+%2C+unfortunately+for+next+Thursday+%2C+in+Texas+in+America+%2C+for+the+execution+of+a+young+34+year-old+man+who+has+been+sentenced+to+death+.+We+shall+call+him+Mr+Hicks+.\n",
        "\n",
        "para_t5 = open('para_t5.txt', 'w')\n",
        "\n",
        "while True:\n",
        "  input_sentence = reader.readline()\n",
        "  if not input_sentence:\n",
        "    break\n",
        "  output = str(paraphrase(input_sentence))[2:-2]\n",
        "  print(output)\n",
        "  para_t5.write(output)\n",
        "  para_t5.write('\\n')\n",
        "\n",
        "para_t5.close()"
      ],
      "metadata": {
        "id": "1RlWinWHquBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "IgNGQWFDli0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "para_bart_reader = open('para_bart.txt', 'r')"
      ],
      "metadata": {
        "id": "LFqqE0wXIace"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para_t5_reader = open('para_t5.txt', 'r')"
      ],
      "metadata": {
        "id": "kHVfrod2IeNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_cohesive_markers = [\"because\", \"besides\", \"but\", \"consequently\", \"despite\", \"except\", \"further\", \"furthermore\", \"hence\", \"however\", \"instead\", \"maybe\", \"moreover\", \"nevertheless\", \"otherwise\",  \"since\", \"so\", \"therefore\",  \"though\", \"thus\",  \"yet\", \"concerning\"]\n",
        "bi_cohesive_markers = [[\"as\",\"for\"], [\"as\",\"to\"], [\"even\", \"if\"], [\"even\",\"though\"], [\"in\", \"addition\"], [\"in\",\"conclusion\"], [\"in\",\"spite\"], [\"referring\",\"to\"], [\"the\", \"former\"], [\"the\", \"latter\"], [\"this\", \"implies\"]]\n",
        "tri_cohesive_markers = [[\"in\",\"other\",\"words\"], [\"is\",\"to\",\"say\"], [\"on\",\"account\",\"of\"], [\"on\",\"the\",\"contrary\"], [\"with\",\"reference\",\"to\"], [\"with\",\"regard\",\"to\"]]\n",
        "quat_cohesive_markers = [\"on\",\"the\",\"other\",\"hand\"]"
      ],
      "metadata": {
        "id": "VtVOPCYRHv6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_from_root(tok, count):\n",
        "  #print(\"tok \", tok)\n",
        "  if tok.dep_ == 'ROOT':\n",
        "    #print(\"count \", count)\n",
        "    return count\n",
        "  else:\n",
        "    return dist_from_root(tok.head, count+1)\n",
        "\n",
        "def summed_dist_for_sent_length(sum_dist, sent_length):\n",
        "  if sent_length not in dist_dict:\n",
        "    dist_dict[sent_length] = []\n",
        "  dist_dict[sent_length].append(sum_dist)\n",
        "\n",
        "def summed_dist(sent):\n",
        "  doc = nlp(sent)\n",
        "  total_count = 0\n",
        "\n",
        "  for token in doc:\n",
        "    total_count += dist_from_root(token,0)\n",
        "    #print(total_count)\n",
        "\n",
        "  sent_len = len(sent.split())\n",
        "\n",
        "  summed_dist_for_sent_length(total_count,sent_len)\n",
        "\n",
        "def collect_all_unique_tokens(sent):\n",
        "  doc = nlp(sent)\n",
        "  for token in doc:\n",
        "    list_all_tokens.append(token)\n",
        "    list_pos_tags.append(token.pos_)\n",
        "    if token.lemma_ not in list_unique_tokens:\n",
        "      list_unique_tokens.append(token.lemma_)\n",
        "\n",
        "def individual_sent_tokens(sent):\n",
        "  temp_tokens = []\n",
        "  uniq_tokens = []\n",
        "  doc = nlp(sent)\n",
        "  for token in doc:\n",
        "    temp_tokens.append(token)\n",
        "    if token.lemma_ not in uniq_tokens:\n",
        "      uniq_tokens.append(token.lemma_)\n",
        "  return temp_tokens, uniq_tokens"
      ],
      "metadata": {
        "id": "hqLouQoiH3YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_cohesive_fx(sent, cohesive_list):\n",
        "  #print(list_all_tokens)\n",
        "  count_cohesive = 0\n",
        "  #print(uni_cohesive_markers)\n",
        "  for word in sent:\n",
        "    if str(word).lower() in uni_cohesive_markers:\n",
        "      count_cohesive += 1\n",
        "  # print(count_cohesive)\n",
        "\n",
        "  first_word = str(sent[0]).lower()\n",
        "  for word in sent[1:]:\n",
        "    bigram = []\n",
        "    bigram.append(first_word)\n",
        "    second_word = str(word).lower()\n",
        "    bigram.append(second_word)\n",
        "    #print(bigram)\n",
        "    if bigram in bi_cohesive_markers:\n",
        "      count_cohesive += 1\n",
        "    first_word = second_word\n",
        "  # print(count_cohesive)\n",
        "\n",
        "  first_word = str(sent[0]).lower()\n",
        "  second_word = str(sent[1]).lower()\n",
        "  for word in sent[2:]:\n",
        "    trigram = []\n",
        "    trigram.append(first_word)\n",
        "    trigram.append(second_word)\n",
        "    third_word = str(word).lower()\n",
        "    trigram.append(third_word)\n",
        "    #print(trigram)\n",
        "    if trigram in tri_cohesive_markers:\n",
        "      count_cohesive += 1\n",
        "    first_word = second_word\n",
        "    second_word = third_word\n",
        "  # print(count_cohesive)\n",
        "\n",
        "  first_word = str(sent[0]).lower()\n",
        "  second_word = str(sent[1]).lower()\n",
        "  third_word = str(sent[2]).lower()\n",
        "  for word in sent[3:]:\n",
        "    quatgram = []\n",
        "    quatgram.append(first_word)\n",
        "    quatgram.append(second_word)\n",
        "    quatgram.append(third_word)\n",
        "    fourth_word = str(word).lower()\n",
        "    quatgram.append(fourth_word)\n",
        "    #print(quatgram)\n",
        "    if quatgram == quat_cohesive_markers:\n",
        "      count_cohesive += 1\n",
        "    first_word = second_word\n",
        "    second_word = third_word\n",
        "    third_word = fourth_word\n",
        "  # cfile.write(count_cohesive)\n",
        "  # cfile.write('\\n')\n",
        "  cohesive_list.append(count_cohesive)\n",
        "  return cohesive_list\n",
        "  # print(count_cohesive)\n",
        "\n",
        "  # print(\"COHESIVE MARKERS: \" , count_cohesive)\n",
        "  # cfile.close()"
      ],
      "metadata": {
        "id": "pMH6IOv3Iloc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count = 0\n",
        "# clist = []\n",
        "\n",
        "cfile = open('ttr.txt', 'w')\n",
        "\n",
        "\n",
        "while True:\n",
        "  line = reader.readline()\n",
        "  if not line:\n",
        "    break\n",
        "  # line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "  line = re.sub(r\"\\s([?.!',](?:\\s|$))\", r'\\1', line)\n",
        "  sent_toks, uniq_toks = individual_sent_tokens(line)\n",
        "  # clist = count_cohesive_fx(sent_toks, clist)\n",
        "  ttr = len(uniq_toks) / len(sent_toks)\n",
        "  cfile.write(str(ttr))\n",
        "  cfile.write('\\n')\n",
        "\n",
        "# for item in clist:\n",
        "cfile.close()\n",
        "\n",
        "\n",
        "  #print(line)\n",
        "  # try:\n",
        "  #   summed_dist(line)\n",
        "  # except:\n",
        "  #   print(\"An exception occurred\")\n",
        "  # count += 1\n",
        "  # if count%5000==0:\n",
        "  #   print(\"Now at line: \", str(count))\n",
        "  # file.write(str(dist))\n",
        "  # file.write('\\n')"
      ],
      "metadata": {
        "id": "_fDi3dipIZQm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}